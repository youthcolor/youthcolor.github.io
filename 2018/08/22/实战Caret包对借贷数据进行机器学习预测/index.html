<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="youthcolor's github blog"><title>实战Caret包对借贷数据进行机器学习预测 | Geekdreams</title><link rel="stylesheet" type="text/css" href="//fonts.css.network/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">实战Caret包对借贷数据进行机器学习预测</h1><a id="logo" href="/.">Geekdreams</a><p class="description">Nothing is difficult to the man who will try.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">实战Caret包对借贷数据进行机器学习预测</h1><div class="post-meta"><a href="/2018/08/22/实战Caret包对借贷数据进行机器学习预测/#comments" class="comment-count"><a id="uyan_count_unit" href="/2018/08/22/实战Caret包对借贷数据进行机器学习预测/"></a>留言</a><p><span class="date">Aug 22, 2018</span><span><a href="/categories/R/" class="category">R</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>机器学习面临的最大挑战之一该选择什么样的学习算法。在R中，不同的算法会有不同的语法、不同的参数调优和不同的数据格式，因此，对于初学者来说，显得比较吃力。</p>
<p>那么，你如何从一个初学者转变为一个数据科学家，建立数百个模型并把它们堆在一起?当然没有捷径可走，但我想不见得非得把数百个机器学习模型都应用一遍，记住每个算法的不同包名，应用每个算法的语法，为每个算法优化参数等。</p>
<p>Caret(分类和回归训练)包，这可能是R中最大的项目。这个包是我们需要知道的，就像要知道Python机器学习中的Scikit-Learn包一样，它几乎可以解决任何一个受监督的机器学习问题。它为几种机器学习算法提供了统一的接口，并标准化了各种各样的任务，如数据分割、预处理、特性选择、变量重要性评估等。<br><a id="more"></a><br>今天，我们将探索研究借贷数据预测问题，展示下Caret包的强大功能。PS：尽管Caret确实简化了很多机器学习工作，但是也没必要在它身上投入太多精力。</p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li>加载数据</li>
<li>数据预处理</li>
<li>数据分割</li>
<li>特征选择</li>
<li>训练模型</li>
<li>参数调优</li>
<li>参数重要性评估</li>
<li>结果预测</li>
</ol>
<h2 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1. 加载数据"></a>1. 加载数据</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># install.packages("caret", dependencies = c("Depends", "Suggests"))</span></div><div class="line"><span class="comment">#Loading caret package</span></div><div class="line"><span class="keyword">library</span>(<span class="string">"caret"</span>)</div><div class="line"><span class="comment">#Loading training data</span></div><div class="line">train&lt;-read.csv(<span class="string">"C:\\Users\\Administrator\\Desktop\\loan\\train_u6lujuX_CVtuZ9i.csv"</span>,</div><div class="line">                stringsAsFactors = <span class="literal">T</span>)</div><div class="line"><span class="comment">#Looking at the structure of caret package.</span></div><div class="line">str(train)</div><div class="line">head(rain)</div><div class="line">Loan_ID Gender Married Dependents    Education Self_Employed ApplicantIncome CoapplicantIncome</div><div class="line"><span class="number">1</span> LP001002   Male      No          <span class="number">0</span>     Graduate            No            <span class="number">5849</span>                 <span class="number">0</span></div><div class="line"><span class="number">2</span> LP001003   Male     Yes          <span class="number">1</span>     Graduate            No            <span class="number">4583</span>              <span class="number">1508</span></div><div class="line"><span class="number">3</span> LP001005   Male     Yes          <span class="number">0</span>     Graduate           Yes            <span class="number">3000</span>                 <span class="number">0</span></div><div class="line"><span class="number">4</span> LP001006   Male     Yes          <span class="number">0</span> Not Graduate            No            <span class="number">2583</span>              <span class="number">2358</span></div><div class="line"><span class="number">5</span> LP001008   Male      No          <span class="number">0</span>     Graduate            No            <span class="number">6000</span>                 <span class="number">0</span></div><div class="line"><span class="number">6</span> LP001011   Male     Yes          <span class="number">2</span>     Graduate           Yes            <span class="number">5417</span>              <span class="number">4196</span></div><div class="line">  LoanAmount Loan_Amount_Term Credit_History Property_Area Loan_Status</div><div class="line"><span class="number">1</span>         <span class="literal">NA</span>              <span class="number">360</span>              <span class="number">1</span>         Urban           Y</div><div class="line"><span class="number">2</span>        <span class="number">128</span>              <span class="number">360</span>              <span class="number">1</span>         Rural           N</div><div class="line"><span class="number">3</span>         <span class="number">66</span>              <span class="number">360</span>              <span class="number">1</span>         Urban           Y</div><div class="line"><span class="number">4</span>        <span class="number">120</span>              <span class="number">360</span>              <span class="number">1</span>         Urban           Y</div><div class="line"><span class="number">5</span>        <span class="number">141</span>              <span class="number">360</span>              <span class="number">1</span>         Urban           Y</div><div class="line"><span class="number">6</span>        <span class="number">267</span>              <span class="number">360</span>              <span class="number">1</span>         Urban           Y</div></pre></td></tr></table></figure>
<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h2><p>在建模之前，通常有个数据预处理，先来看看有没有缺失值。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sum(is.na(train))</div><div class="line">[<span class="number">1</span>] <span class="number">86</span></div></pre></td></tr></table></figure></p>
<p>接下来，我们用KNN算法给数据中的缺失值预测并赋值，在这个过程中，对数据进行了标准化操作。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Imputing missing values using KNN.Also centering and scaling numerical columns</span></div><div class="line">preProcValues &lt;- preProcess(train, method = c(<span class="string">"knnImpute"</span>,<span class="string">"center"</span>,<span class="string">"scale"</span>))</div><div class="line"><span class="keyword">library</span>(<span class="string">'RANN'</span>)</div><div class="line">train_processed &lt;- predict(preProcValues, train)</div><div class="line">sum(is.na(train_processed))</div><div class="line">[<span class="number">1</span>] <span class="number">0</span></div></pre></td></tr></table></figure></p>
<p>使用<em>dummyVars</em>函数将分类变量编码为哑变量。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Converting outcome variable to numeric</span></div><div class="line">train_processed$Loan_Status&lt;-ifelse(train_processed$Loan_Status==<span class="string">'N'</span>,<span class="number">0</span>,<span class="number">1</span>)</div><div class="line">id&lt;-train_processed$Loan_ID</div><div class="line">train_processed$Loan_ID&lt;-<span class="literal">NULL</span></div><div class="line"><span class="comment">#Converting every categorical variable to numerical using dummy variables</span></div><div class="line">dmy &lt;- dummyVars(<span class="string">" ~ ."</span>, data = train_processed,fullRank = <span class="literal">T</span>)</div><div class="line">train_transformed &lt;- data.frame(predict(dmy, newdata = train_processed))</div><div class="line">str(train_transformed)</div><div class="line"><span class="string">'data.frame'</span>:	<span class="number">614</span> obs. of  <span class="number">19</span> variables:</div><div class="line"> $ Gender.Female          : num  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Gender.Male            : num  <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="keyword">...</span></div><div class="line"> $ Married.No             : num  <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Married.Yes            : num  <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="keyword">...</span></div><div class="line"> $ Dependents.0           : num  <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Dependents.1           : num  <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="keyword">...</span></div><div class="line"> $ Dependents.2           : num  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Dependents.3.          : num  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Education.Not.Graduate : num  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Self_Employed.No       : num  <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="keyword">...</span></div><div class="line"> $ Self_Employed.Yes      : num  <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ ApplicantIncome        : num  <span class="number">0.0729</span> -<span class="number">0.1343</span> -<span class="number">0.3934</span> -<span class="number">0.4617</span> <span class="number">0.0976</span> <span class="keyword">...</span></div><div class="line"> $ CoapplicantIncome      : num  -<span class="number">0.554</span> -<span class="number">0.0387</span> -<span class="number">0.554</span> <span class="number">0.2518</span> -<span class="number">0.554</span> <span class="keyword">...</span></div><div class="line"> $ LoanAmount             : num  <span class="number">0.0162</span> -<span class="number">0.2151</span> -<span class="number">0.9395</span> -<span class="number">0.3086</span> -<span class="number">0.0632</span> <span class="keyword">...</span></div><div class="line"> $ Loan_Amount_Term       : num  <span class="number">0.276</span> <span class="number">0.276</span> <span class="number">0.276</span> <span class="number">0.276</span> <span class="number">0.276</span> <span class="keyword">...</span></div><div class="line"> $ Credit_History         : num  <span class="number">0.432</span> <span class="number">0.432</span> <span class="number">0.432</span> <span class="number">0.432</span> <span class="number">0.432</span> <span class="keyword">...</span></div><div class="line"> $ Property_Area.Semiurban: num  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="keyword">...</span></div><div class="line"> $ Property_Area.Urban    : num  <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"> $ Loan_Status            : num  <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="keyword">...</span></div><div class="line"><span class="comment">#Converting the dependent variable back to categorical</span></div><div class="line">train_transformed$Loan_Status&lt;-as.factor(train_transformed$Loan_Status)</div></pre></td></tr></table></figure></p>
<h2 id="3-数据分割"><a href="#3-数据分割" class="headerlink" title="3. 数据分割"></a>3. 数据分割</h2><p>为了防止过度拟合，我们以因变量为准将数据分成两份，便于后续的交叉验证。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Spliting training set into two parts based on outcome: 75% and 25%</span></div><div class="line">index &lt;- createDataPartition(train_transformed$Loan_Status, p=<span class="number">0.75</span>, list=<span class="literal">FALSE</span>)</div><div class="line">trainSet &lt;- train_transformed[ index,]</div><div class="line">testSet &lt;- train_transformed[-index,]</div><div class="line"><span class="comment">#Checking the structure of trainSet</span></div><div class="line">str(trainSet)</div></pre></td></tr></table></figure></p>
<h2 id="4-特征选择"><a href="#4-特征选择" class="headerlink" title="4. 特征选择"></a>4. 特征选择</h2><p>特性选择是建模的极其重要部分，我们将使用递归特性消除方法，以找到用于建模的最佳特性子集。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Feature selection using rfe in caret</span></div><div class="line">control &lt;- rfeControl(functions = rfFuncs,</div><div class="line">                      method = <span class="string">"repeatedcv"</span>,</div><div class="line">                      repeats = <span class="number">3</span>,</div><div class="line">                      verbose = <span class="literal">FALSE</span>)</div><div class="line">outcomeName&lt;-<span class="string">'Loan_Status'</span></div><div class="line">predictors&lt;-names(trainSet)[!names(trainSet) %<span class="keyword">in</span>% outcomeName]</div><div class="line">Loan_Pred_Profile &lt;- rfe(trainSet[,predictors], trainSet[,outcomeName],</div><div class="line">                         rfeControl = control)</div><div class="line">Loan_Pred_Profile</div><div class="line">Recursive feature selection</div><div class="line">Outer resampling method: Cross-Validated (<span class="number">10</span> fold, repeated <span class="number">3</span> times) </div><div class="line">Resampling performance over subset size:</div><div class="line"> Variables Accuracy  Kappa AccuracySD KappaSD Selected</div><div class="line">         <span class="number">4</span>   <span class="number">0.8027</span> <span class="number">0.4843</span>    <span class="number">0.04251</span>  <span class="number">0.1198</span>         </div><div class="line">         <span class="number">8</span>   <span class="number">0.8122</span> <span class="number">0.5021</span>    <span class="number">0.04127</span>  <span class="number">0.1210</span>         </div><div class="line">        <span class="number">16</span>   <span class="number">0.8106</span> <span class="number">0.5029</span>    <span class="number">0.03919</span>  <span class="number">0.1147</span>         </div><div class="line">        <span class="number">18</span>   <span class="number">0.8142</span> <span class="number">0.5097</span>    <span class="number">0.03693</span>  <span class="number">0.1098</span>        *</div><div class="line">The top <span class="number">5</span> variables (out of <span class="number">18</span>):</div><div class="line">   Credit_History, Property_Area.Semiurban, CoapplicantIncome, ApplicantIncome, LoanAmount</div><div class="line"><span class="comment">#Taking only the top 5 predictors</span></div><div class="line">predictors&lt;-c(<span class="string">"Credit_History"</span>, <span class="string">"LoanAmount"</span>, <span class="string">"Loan_Amount_Term"</span>, <span class="string">"ApplicantIncome"</span>, <span class="string">"CoapplicantIncome"</span>)</div></pre></td></tr></table></figure></p>
<h2 id="5-训练模型"><a href="#5-训练模型" class="headerlink" title="5. 训练模型"></a>5. 训练模型</h2><p>这可能是Caret从其他任何可用的方案中能脱颖而出的原因，它提供了使用一致的语法实现200多个机器学习算法的能力。如果想查看Caret支持的所有算法的列表，你可以使用<em>names(getModelInfo())</em>。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">names(getModelInfo())</div><div class="line">[<span class="number">1</span>] <span class="string">"ada"</span>                 <span class="string">"AdaBag"</span>              <span class="string">"AdaBoost.M1"</span>         <span class="string">"adaboost"</span>           </div><div class="line">[<span class="number">5</span>] <span class="string">"amdai"</span>               <span class="string">"ANFIS"</span>               <span class="string">"avNNet"</span>              <span class="string">"awnb"</span>               </div><div class="line">[<span class="number">9</span>] <span class="string">"awtan"</span>               <span class="string">"bag"</span>                 <span class="string">"bagEarth"</span>            <span class="string">"bagEarthGCV"</span>        </div><div class="line">[<span class="number">13</span>] <span class="string">"bagFDA"</span>              <span class="string">"bagFDAGCV"</span>           <span class="string">"bam"</span>                 <span class="string">"bartMachine"</span>        </div><div class="line"><span class="keyword">...</span> </div><div class="line">[<span class="number">225</span>] <span class="string">"svmSpectrumString"</span>   <span class="string">"tan"</span>                 <span class="string">"tanSearch"</span>           <span class="string">"treebag"</span>            </div><div class="line">[<span class="number">229</span>] <span class="string">"vbmpRadial"</span>          <span class="string">"vglmAdjCat"</span>          <span class="string">"vglmContRatio"</span>       <span class="string">"vglmCumulative"</span>     </div><div class="line">[<span class="number">233</span>] <span class="string">"widekernelpls"</span>       <span class="string">"WM"</span>                  <span class="string">"wsrf"</span>                <span class="string">"xgbLinear"</span>          </div><div class="line">[<span class="number">237</span>] <span class="string">"xgbTree"</span>             <span class="string">"xyf"</span></div></pre></td></tr></table></figure></p>
<p>我们可以简单地应用大量具有相似语法的算法。例如，应用GBM、随机森林、神经网络、逻辑回归贝叶斯、XGBTree和支持向量机。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">model_gbm&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'gbm'</span>)</div><div class="line">model_rf&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'rf'</span>)</div><div class="line">model_nnet&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'nnet'</span>)</div><div class="line">model_glm&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'glm'</span>)</div><div class="line">model_nb&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'nb'</span>)</div><div class="line">model_xgbTree&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'xgbTree'</span>)</div><div class="line">model_svmRadial&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'svmRadial'</span>)</div></pre></td></tr></table></figure></p>
<p>您可以使用参数调优技术进一步优化所有这些算法中的参数。</p>
<h2 id="6-参数调优"><a href="#6-参数调优" class="headerlink" title="6. 参数调优"></a>6. 参数调优</h2><p>使用Caret优化参数是非常容易的。通常，Caret中的参数调优工作如下:</p>
<p><img src="http://wx3.sinaimg.cn/mw690/e621a9abgy1flofbhhvp6j20gv06njss.jpg" alt="image"></p>
<p>几乎调优过程中的每一个步骤都是可以定制的。在默认情况下使用一组参数来评估模型性能的重新采样技术是引导程序，但是它提供了使用k-交叉、重复k-交叉以及指定可选交叉验证(LOOCV)的替代方法。在本例中，我们将使用5倍的交叉验证重复5次。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">fitControl &lt;- trainControl(</div><div class="line">  method = <span class="string">"repeatedcv"</span>,</div><div class="line">  number = <span class="number">5</span>,</div><div class="line">  repeats = <span class="number">5</span>)</div></pre></td></tr></table></figure></p>
<p>如果没有定义参数的搜索空间，那么Caret将使用每个可调参数的3个随机值，并使用交叉验证结果来查找该算法的最佳参数集。除此之外，还有两种调优参数的方法：</p>
<h3 id="6-1-使用tuneGrid"><a href="#6-1-使用tuneGrid" class="headerlink" title="6.1 使用tuneGrid"></a>6.1 使用tuneGrid</h3><p>要找到可以调优的模型的参数，您可以使用<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">modelLookup(model=<span class="string">'gbm'</span>)</div><div class="line">model         parameter                   label forReg forClass probModel</div><div class="line"><span class="number">1</span>   gbm           n.trees   <span class="comment"># Boosting Iterations   TRUE     TRUE      TRUE</span></div><div class="line"><span class="number">2</span>   gbm interaction.depth          Max Tree Depth   <span class="literal">TRUE</span>     <span class="literal">TRUE</span>      <span class="literal">TRUE</span></div><div class="line"><span class="number">3</span>   gbm         shrinkage               Shrinkage   <span class="literal">TRUE</span>     <span class="literal">TRUE</span>      <span class="literal">TRUE</span></div><div class="line"><span class="number">4</span>   gbm    n.minobsinnode Min. Terminal Node Size   <span class="literal">TRUE</span>     <span class="literal">TRUE</span>      <span class="literal">TRUE</span></div><div class="line"><span class="comment">#Creating grid</span></div><div class="line">grid &lt;- expand.grid(n.trees=c(<span class="number">10</span>,<span class="number">20</span>,<span class="number">50</span>,<span class="number">100</span>,<span class="number">500</span>,<span class="number">1000</span>),shrinkage=c(<span class="number">0.01</span>,<span class="number">0.05</span>,<span class="number">0.1</span>,<span class="number">0.5</span>),n.minobsinnode = c(<span class="number">3</span>,<span class="number">5</span>,<span class="number">10</span>),interaction.depth=c(<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>))</div><div class="line"><span class="comment"># training the model</span></div><div class="line">model_gbm&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'gbm'</span>,trControl=fitControl,tuneGrid=grid)</div><div class="line"><span class="comment"># summarizing the model</span></div><div class="line">print(model_gbm)</div><div class="line">Stochastic Gradient Boosting </div><div class="line"><span class="number">461</span> samples</div><div class="line">  <span class="number">5</span> predictor</div><div class="line">  <span class="number">2</span> classes: <span class="string">'0'</span>, <span class="string">'1'</span> </div><div class="line">No pre-processing</div><div class="line">Resampling: Cross-Validated (<span class="number">5</span> fold, repeated <span class="number">5</span> times) </div><div class="line">Summary of sample sizes: <span class="number">368</span>, <span class="number">369</span>, <span class="number">370</span>, <span class="number">368</span>, <span class="number">369</span>, <span class="number">369</span>, <span class="keyword">...</span> </div><div class="line">Resampling results across tuning parameters:</div><div class="line">  shrinkage  interaction.depth  n.minobsinnode  n.trees  Accuracy </div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">3</span>                <span class="number">10</span>     <span class="number">0.6876416</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">3</span>                <span class="number">20</span>     <span class="number">0.6876416</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">3</span>                <span class="number">50</span>     <span class="number">0.8243466</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">3</span>               <span class="number">100</span>     <span class="number">0.8243466</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">3</span>               <span class="number">500</span>     <span class="number">0.8213125</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">3</span>              <span class="number">1000</span>     <span class="number">0.8178246</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">5</span>                <span class="number">10</span>     <span class="number">0.6876416</span></div><div class="line">  <span class="number">0.01</span>        <span class="number">1</span>                  <span class="number">5</span>                <span class="number">20</span>     <span class="number">0.6876416</span></div><div class="line">  <span class="keyword">...</span></div><div class="line"> [ reached getOption(<span class="string">"max.print"</span>) -- omitted <span class="number">50</span> rows ]</div><div class="line">Accuracy was used to select the optimal model using  the largest value.</div><div class="line">The final values used <span class="keyword">for</span> the model were n.trees = <span class="number">20</span>, interaction.depth</div><div class="line"> = <span class="number">1</span>, shrinkage = <span class="number">0.1</span> and n.minobsinnode = <span class="number">3.</span></div><div class="line">plot(model_gbm)</div></pre></td></tr></table></figure></p>
<p><img src="http://wx1.sinaimg.cn/mw690/e621a9abgy1flofxq76u7j20p00le3yt.jpg" alt="image"></p>
<p>对于在扩展.grid()中列出的所有参数组合，将使用交叉验证创建和测试一个模型。使用最好的交叉验证性能的参数集将被用来创建最终的模型。</p>
<h3 id="6-2-使用tuneLength"><a href="#6-2-使用tuneLength" class="headerlink" title="6.2. 使用tuneLength"></a>6.2. 使用tuneLength</h3><p>与为每个调优参数指定精确值相反，我们可以简单地要求它通过tuneLength为每个调优参数使用任意数量的可能值。让我们尝试一个使用tuneLength=10的例子。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#using tune length</span></div><div class="line">model_gbm&lt;-train(trainSet[,predictors],trainSet[,outcomeName],method=<span class="string">'gbm'</span>,trControl=fitControl,tuneLength=<span class="number">10</span>)</div><div class="line">print(model_gbm)</div><div class="line"><span class="keyword">...</span></div><div class="line">Tuning parameter <span class="string">'shrinkage'</span> was held constant at a value of <span class="number">0.1</span></div><div class="line">Tuning parameter <span class="string">'n.minobsinnode'</span> was</div><div class="line"> held constant at a value of <span class="number">10</span></div><div class="line">Accuracy was used to select the optimal model using  the largest value.</div><div class="line">The final values used <span class="keyword">for</span> the model were n.trees = <span class="number">50</span>, interaction.depth = <span class="number">1</span>, shrinkage = <span class="number">0.1</span></div><div class="line"> and n.minobsinnode = <span class="number">10.</span></div><div class="line">plot(model_gbm)</div></pre></td></tr></table></figure></p>
<p><img src="http://wx3.sinaimg.cn/mw690/e621a9abgy1flogag16gwj20p00leweq.jpg" alt="image"></p>
<p>这里，保持shrinkage和n.minobsinnode参数不变。n.trees和interaction.depth改变10个值，并使用最好的组合来训练最终模型。</p>
<h2 id="7-变量重要性"><a href="#7-变量重要性" class="headerlink" title="7. 变量重要性"></a>7. 变量重要性</h2><p>Caret还通过使用varImp()对任何模型进行变量的评估。让我们来看看我们创建的四个模型的变量的重要性。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Checking variable importance for GBM</span></div><div class="line"><span class="comment">#Variable Importance</span></div><div class="line">varImp(object=model_gbm)</div><div class="line"><span class="comment">#Plotting Varianle importance for GBM</span></div><div class="line">plot(varImp(object=model_gbm),main=<span class="string">"GBM - Variable Importance"</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://wx1.sinaimg.cn/mw690/e621a9abgy1flojiw71isj20br0a20sk.jpg" alt="image"><br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Checking variable importance for RF</span></div><div class="line">varImp(object=model_rf)</div><div class="line"><span class="comment">#Plotting Varianle importance for Random Forest</span></div><div class="line">plot(varImp(object=model_rf),main=<span class="string">"RF - Variable Importance"</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://wx3.sinaimg.cn/mw690/e621a9abgy1flojlmzgtbj20br0a23yc.jpg" alt="image"><br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Checking variable importance for NNET</span></div><div class="line">varImp(object=model_nnet)</div><div class="line"><span class="comment">#Plotting Variable importance for Neural Network</span></div><div class="line">plot(varImp(object=model_nnet),main=<span class="string">"NNET - Variable Importance"</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://wx3.sinaimg.cn/mw690/e621a9abgy1flojnxktmqj20br0a20sk.jpg" alt="image"><br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Checking variable importance for GLM</span></div><div class="line">varImp(object=model_glm)</div><div class="line"><span class="comment">#Plotting Variable importance for GLM</span></div><div class="line">plot(varImp(object=model_glm),main=<span class="string">"GLM - Variable Importance"</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://wx3.sinaimg.cn/mw690/e621a9abgy1flojqfcdgyj20br0a2744.jpg" alt="image"></p>
<p>很明显，不同模型的变量重要性是不同的。从不同的模型中得到的变量重要性的两个主要用途是:</p>
<ul>
<li>对大多数模型来说重要的预测因子代表着真正重要的预测因子。</li>
<li>组合预测中，我们应该使用那些具有显著不同重要性的模型进行预测，因为他们的预测也会有所不同。但必须确保所有这些都是足够准确的。<h2 id="8-结果预测"><a href="#8-结果预测" class="headerlink" title="8. 结果预测"></a>8. 结果预测</h2>为了预测测试集的相关变量，Caret提供了predict.train()函数。您需要指定模型名称、测试数据。对于分类问题，Caret还提供了另一个名为<em>type</em>的特性，可以设置为<em>prob</em>或<em>raw</em>。对于类型<em>raw</em>，预测只是测试数据的结果类，而对于类型<em>prob</em>，它将给出在不同类型的结果变量中出现的每个观察结果的概率。</li>
</ul>
<p>让我们来看看我们的GBM模型的预测:<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Predictions</span></div><div class="line">predictions&lt;-predict.train(object=model_gbm,testSet[,predictors],type=<span class="string">"raw"</span>)</div><div class="line">confusionMatrix(predictions,testSet[,outcomeName])</div><div class="line">Confusion Matrix and Statistics</div><div class="line">          Reference</div><div class="line">Prediction   <span class="number">0</span>   <span class="number">1</span></div><div class="line">         <span class="number">0</span>  <span class="number">14</span>   <span class="number">2</span></div><div class="line">         <span class="number">1</span>  <span class="number">34</span> <span class="number">103</span></div><div class="line">               Accuracy : <span class="number">0.7647</span>          </div><div class="line">                 <span class="number">95</span>% CI : (<span class="number">0.6894</span>, <span class="number">0.8294</span>)</div><div class="line">    No Information Rate : <span class="number">0.6863</span>          </div><div class="line">    P-Value [Acc &gt; NIR] : <span class="number">0.02055</span>         </div><div class="line">                  Kappa : <span class="number">0.3328</span>          </div><div class="line"> Mcnemar<span class="string">'s Test P-Value : 2.383e-07       </span></div><div class="line">            Sensitivity : 0.2917          </div><div class="line">            Specificity : 0.9810          </div><div class="line">         Pos Pred Value : 0.8750          </div><div class="line">         Neg Pred Value : 0.7518          </div><div class="line">             Prevalence : 0.3137          </div><div class="line">         Detection Rate : 0.0915          </div><div class="line">   Detection Prevalence : 0.1046          </div><div class="line">      Balanced Accuracy : 0.6363          </div><div class="line">       'Positive<span class="string">' Class : 0</span></div></pre></td></tr></table></figure></p>
<p>RF的预测：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Predictions</span></div><div class="line">predictions&lt;-predict.train(object=model_rf,testSet[,predictors],type=<span class="string">"raw"</span>)</div><div class="line">confusionMatrix(predictions,testSet[,outcomeName])</div><div class="line">Confusion Matrix and Statistics</div><div class="line">          Reference</div><div class="line">Prediction  <span class="number">0</span>  <span class="number">1</span></div><div class="line">         <span class="number">0</span> <span class="number">17</span>  <span class="number">6</span></div><div class="line">         <span class="number">1</span> <span class="number">31</span> <span class="number">99</span></div><div class="line">               Accuracy : <span class="number">0.7582</span>          </div><div class="line">                 <span class="number">95</span>% CI : (<span class="number">0.6824</span>, <span class="number">0.8237</span>)</div><div class="line">    No Information Rate : <span class="number">0.6863</span>          </div><div class="line">    P-Value [Acc &gt; NIR] : <span class="number">0.0315</span>          </div><div class="line">                  Kappa : <span class="number">0.3459</span>          </div><div class="line"> Mcnemar<span class="string">'s Test P-Value : 7.961e-05       </span></div><div class="line">            Sensitivity : 0.3542          </div><div class="line">            Specificity : 0.9429          </div><div class="line">         Pos Pred Value : 0.7391          </div><div class="line">         Neg Pred Value : 0.7615          </div><div class="line">             Prevalence : 0.3137          </div><div class="line">         Detection Rate : 0.1111          </div><div class="line">   Detection Prevalence : 0.1503          </div><div class="line">      Balanced Accuracy : 0.6485          </div><div class="line">       'Positive<span class="string">' Class : 0</span></div></pre></td></tr></table></figure></p>
<p>NNET的预测：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Predictions</span></div><div class="line">predictions&lt;-predict.train(object=model_nnet,testSet[,predictors],type=<span class="string">"raw"</span>)</div><div class="line">confusionMatrix(predictions,testSet[,outcomeName])</div><div class="line">Confusion Matrix and Statistics</div><div class="line">          Reference</div><div class="line">Prediction   <span class="number">0</span>   <span class="number">1</span></div><div class="line">         <span class="number">0</span>  <span class="number">14</span>   <span class="number">2</span></div><div class="line">         <span class="number">1</span>  <span class="number">34</span> <span class="number">103</span></div><div class="line">               Accuracy : <span class="number">0.7647</span>          </div><div class="line">                 <span class="number">95</span>% CI : (<span class="number">0.6894</span>, <span class="number">0.8294</span>)</div><div class="line">    No Information Rate : <span class="number">0.6863</span>          </div><div class="line">    P-Value [Acc &gt; NIR] : <span class="number">0.02055</span>         </div><div class="line">                  Kappa : <span class="number">0.3328</span>          </div><div class="line"> Mcnemar<span class="string">'s Test P-Value : 2.383e-07       </span></div><div class="line">            Sensitivity : 0.2917          </div><div class="line">            Specificity : 0.9810          </div><div class="line">         Pos Pred Value : 0.8750          </div><div class="line">         Neg Pred Value : 0.7518          </div><div class="line">             Prevalence : 0.3137          </div><div class="line">         Detection Rate : 0.0915          </div><div class="line">   Detection Prevalence : 0.1046          </div><div class="line">      Balanced Accuracy : 0.6363          </div><div class="line">       'Positive<span class="string">' Class : 0</span></div></pre></td></tr></table></figure></p>
<p>GLM的预测：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Predictions</span></div><div class="line">predictions&lt;-predict.train(object=model_glm,testSet[,predictors],type=<span class="string">"raw"</span>)</div><div class="line">confusionMatrix(predictions,testSet[,outcomeName])</div><div class="line">Confusion Matrix and Statistics</div><div class="line">          Reference</div><div class="line">Prediction   <span class="number">0</span>   <span class="number">1</span></div><div class="line">         <span class="number">0</span>  <span class="number">14</span>   <span class="number">2</span></div><div class="line">         <span class="number">1</span>  <span class="number">34</span> <span class="number">103</span></div><div class="line">               Accuracy : <span class="number">0.7647</span>          </div><div class="line">                 <span class="number">95</span>% CI : (<span class="number">0.6894</span>, <span class="number">0.8294</span>)</div><div class="line">    No Information Rate : <span class="number">0.6863</span>          </div><div class="line">    P-Value [Acc &gt; NIR] : <span class="number">0.02055</span>         </div><div class="line">                  Kappa : <span class="number">0.3328</span>          </div><div class="line"> Mcnemar<span class="string">'s Test P-Value : 2.383e-07       </span></div><div class="line">            Sensitivity : 0.2917          </div><div class="line">            Specificity : 0.9810          </div><div class="line">         Pos Pred Value : 0.8750          </div><div class="line">         Neg Pred Value : 0.7518          </div><div class="line">             Prevalence : 0.3137          </div><div class="line">         Detection Rate : 0.0915          </div><div class="line">   Detection Prevalence : 0.1046          </div><div class="line">      Balanced Accuracy : 0.6363          </div><div class="line">       'Positive<span class="string">' Class : 0</span></div></pre></td></tr></table></figure></p>
</div><div class="tags"><a href="/tags/机器学习/">机器学习</a><a href="/tags/Caret预测/">Caret预测</a><a href="/tags/数据预处理/">数据预处理</a><a href="/tags/数据分割/">数据分割</a><a href="/tags/特征选择/">特征选择</a><a href="/tags/参数调优/">参数调优</a><a href="/tags/变量重要性评估/">变量重要性评估</a></div><div class="post-share"><div class="jiathis_style"><span class="jiathis_txt">分享到：</span><a class="jiathis_button_tsina"></a><a class="jiathis_button_qzone"></a><a class="jiathis_button_weixin"></a><a class="jiathis_button_fb"></a><a class="jiathis_button_linkedin"></a><a class="jiathis_button_twitter"></a><a class="jiathis_button_ydnote"></a><a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis"></a><a class="jiathis_counter_style"></a></div></div><div class="post-nav"><a href="/2018/08/22/侦测欺诈交易/" class="pre">侦测欺诈交易</a><a href="/2018/08/22/购物篮关联规则分析/" class="next">购物篮关联规则分析</a></div><div id="comments"><div id="uyan_frame"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#目录"><span class="toc-text">目录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-加载数据"><span class="toc-text">1. 加载数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-数据预处理"><span class="toc-text">2. 数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-数据分割"><span class="toc-text">3. 数据分割</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-特征选择"><span class="toc-text">4. 特征选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-训练模型"><span class="toc-text">5. 训练模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-参数调优"><span class="toc-text">6. 参数调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-使用tuneGrid"><span class="toc-text">6.1 使用tuneGrid</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-使用tuneLength"><span class="toc-text">6.2. 使用tuneLength</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-变量重要性"><span class="toc-text">7. 变量重要性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-结果预测"><span class="toc-text">8. 结果预测</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/R使用keras包和lime包实现图像分类并添加解释/">R使用keras包和lime包实现图像分类并添加解释</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/使用rvest抓取NBA历史比赛数据/">使用rvest抓取NBA历史比赛数据</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/R机器学习之股票预测初探/">R机器学习之股票预测初探</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/R中如何对量化策略进行回测/">R中如何对量化策略进行回测</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/data.table() vs data.frame() – R大数据集处理/">data.table() vs data.frame() – R大数据集处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/R中的大数据分析/">R中的大数据分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/使用H2O和data.table构建R大数据集模型/">使用H2O和data.table构建R大数据集模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/侦测欺诈交易/">侦测欺诈交易</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/实战Caret包对借贷数据进行机器学习预测/">实战Caret包对借贷数据进行机器学习预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/购物篮关联规则分析/">购物篮关联规则分析</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python-R/">Python + R</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/R/">R</a><span class="category-list-count">10</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/离群值侦测排序/" style="font-size: 15px;">离群值侦测排序</a> <a href="/tags/量化金融/" style="font-size: 15px;">量化金融</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/聚类/" style="font-size: 15px;">聚类</a> <a href="/tags/线性回归/" style="font-size: 15px;">线性回归</a> <a href="/tags/股票预测/" style="font-size: 15px;">股票预测</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/特征选取/" style="font-size: 15px;">特征选取</a> <a href="/tags/keras/" style="font-size: 15px;">keras</a> <a href="/tags/图像分类/" style="font-size: 15px;">图像分类</a> <a href="/tags/lime/" style="font-size: 15px;">lime</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/网络爬虫/" style="font-size: 15px;">网络爬虫</a> <a href="/tags/H2O/" style="font-size: 15px;">H2O</a> <a href="/tags/欺诈侦测/" style="font-size: 15px;">欺诈侦测</a> <a href="/tags/半监督分类/" style="font-size: 15px;">半监督分类</a> <a href="/tags/类失衡/" style="font-size: 15px;">类失衡</a> <a href="/tags/贝叶斯分类器/" style="font-size: 15px;">贝叶斯分类器</a> <a href="/tags/AdaBoost分类器/" style="font-size: 15px;">AdaBoost分类器</a> <a href="/tags/决策精确度/" style="font-size: 15px;">决策精确度</a> <a href="/tags/回溯精确度/" style="font-size: 15px;">回溯精确度</a> <a href="/tags/交叉验证/" style="font-size: 15px;">交叉验证</a> <a href="/tags/回测/" style="font-size: 15px;">回测</a> <a href="/tags/Caret预测/" style="font-size: 15px;">Caret预测</a> <a href="/tags/数据预处理/" style="font-size: 15px;">数据预处理</a> <a href="/tags/数据分割/" style="font-size: 15px;">数据分割</a> <a href="/tags/特征选择/" style="font-size: 15px;">特征选择</a> <a href="/tags/参数调优/" style="font-size: 15px;">参数调优</a> <a href="/tags/变量重要性评估/" style="font-size: 15px;">变量重要性评估</a> <a href="/tags/购物篮/" style="font-size: 15px;">购物篮</a> <a href="/tags/关联规则/" style="font-size: 15px;">关联规则</a> <a href="/tags/推荐算法/" style="font-size: 15px;">推荐算法</a> <a href="/tags/逻辑回归/" style="font-size: 15px;">逻辑回归</a> <a href="/tags/决策树/" style="font-size: 15px;">决策树</a> <a href="/tags/支持向量机/" style="font-size: 15px;">支持向量机</a> <a href="/tags/朴素贝叶斯/" style="font-size: 15px;">朴素贝叶斯</a> <a href="/tags/最近邻（KNN）/" style="font-size: 15px;">最近邻（KNN）</a> <a href="/tags/K-均值/" style="font-size: 15px;">K-均值</a> <a href="/tags/随机森林/" style="font-size: 15px;">随机森林</a> <a href="/tags/降维算法/" style="font-size: 15px;">降维算法</a> <a href="/tags/梯度下降算法/" style="font-size: 15px;">梯度下降算法</a> <a href="/tags/GBM/" style="font-size: 15px;">GBM</a> <a href="/tags/XGBoost/" style="font-size: 15px;">XGBoost</a> <a href="/tags/LightGBM/" style="font-size: 15px;">LightGBM</a> <a href="/tags/CatBoost/" style="font-size: 15px;">CatBoost</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://weibo.com/youthcolor" title="Geekdreams" target="_blank">Geekdreams</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">youthcolor.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>var jiathis_config={
    data_track_clickback:true,
    summary:"",
    shortUrl:true,
    hideMore:false
}</script><script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script><script src="http://v2.uyan.cc/code/uyan.js?uid=2136627"></script></body></html>